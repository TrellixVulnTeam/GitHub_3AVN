BIG DATA -> É UM CONCEITO (ELE TEM PROBLEMAS PRÓPRIOS DELE PARA RESOLVER(NAO SUBSTITUI O BI)) - VOCÊ PRECISA OU NÃO DE BIG DATA PARA RESOLVER NOSSO PROBLEMA?

--- CONCEITO DE BIG DATA ----

	CRITÉRIOS DE BIG DATA
	1 - VOLUME DOS DADOS
	2 - VARIEDADE DOS DADOS
	3 - VERACIDADE (DADOS VERDADEIROS)
	4 - VALOR (EXTRAIR VALOR DOS DADOS)
	5 - VELOCIDADE


HADOOP (TOTALMENTE OPEN SOURCE) -> CLOUDERA OFERECE SUPORTE - É UM ECOSSISTEMA PARA ATENDER ESSE CONCEITO DE BIG DATA

### GRAVAÇÃO/DISTRIBUIÇÃO/PROCESSAMENTO DE ARQUIVOS NO HADOOP ###

	PORQUE O HADOOP É TOLERANTE A FALHAS? -> PORQUE O HADOOP VAI REPLICAR CADA ARQUIVO DO DADO 3 VEZES COMO SE FOSSE UM BACKUP. SE UMA     MAQUINA FALHAR ELE VAI TER ESSE ARQUIVO GUARDADO EM OUTRA MAQUINA.

	COMO O HADOOP SABE QUAL PARTE (QUE ELE REPLICOU) CORRESPONDE A CADA ARQUIVO? -> ELE TEM UM BANCO DE DADOS RELACIONAL QUE GRAVA A POSIÇÃO DOS ARQUIVOS.

	TODAS AS PARTES DOS ARQUIVOS SÃO GUARDADAS(DISTRIBUIDAS PELA MAQUINAS) AO MESMO TEMPO, DESTA FORMA GARANTE A INTEGRIDADE DO DADO.


#####################################################################


## O QUE É UM CLUSTER ##

	- UM CLUSTER É UM CONJUNTO DE MAQUINAS INTERLIGADAS EM UMA REDE COM A FINALIDADE DE ARMAZENAR/PROCESSAR UMA INFORMÇÃO DE FORMA DISTRIBUIDA.

	- CADA NÓ DO CLUSTER É CHAMADO DE DATANODE -> UM NÓ É UMA MAQUINA. (AQUI OS DADOS SÃO PROCESSADOS)

## MASTERES ###

	- NAME NODE É UM ORQUESTRADOR (ELE ALOCADA EM MEMORIA O ENDEREÇO DE CADA ARQUIVO DO CLUSTER). -> SE PERDER ESSE MASTER VC PERDE O SEU DATALAKE.

	- SECUNDARY NAMENOME -> ELE É UMA ESTRUTURA DE TOLERANCIA A FALHA DO NAMENODE.


## CLIENTNODE ##

	- É A MAQUINA QUE ULTILIZAMOS PARA ACESSAR OS CLUSTERS (ENVIA JOB PARA PROCESSAMENTE) -> NAVEGAMOS DENTRO DO HDFS


#####################################################################


-------- FERRAMENTAS DO HADOOP -------

	MAP REDUCE -> FRAMEWORK PARA PROCESSAMENTO DISTRUIDO
	YARN -> SISTEMA PARA GERENCIAMENTO DE JOBS
	HIVE
	HDFS -> SISTEMA DE ARMAZENAMENTO DE ARQUIVOS
	NIFE
	FLUME

	##COMPLEXO##
	SPARK - LINGUAGEM QUE O HADOOOP RODA


### HDFS ###

	O QUE É O HDFS -> ARMAZENAMENTO DISTRIBUIDO DO HADOOP.

	DINAMICA DE ACESSO/ QUAL RESULTADO QUE TRAS PARA A GENTE

	- O HDFS É ACESSADO ATRAVÉS DO CLIENTNODE.

	QUANDO ACESSAMOS O CLIENTNODE (via ssh) NÓS TEMOS DUAS OPÇÕES:   *CLIENTNODE* É ACESSADO VIA TERMINAL/NAO TEM INTERFACE GRAFICA

	1 - ACESSAMOS OS ARQUIVOS LOCAIS DA MAQUINA - SE DIGITAR (LS) VAI MOSTRAR ARQUIVOS DA MAQUINA LOCAL

	2 - ACESSAMOS OS  ARQUIVOS CONTIDOS DENTRO DO HDFS. - SE DIGITAR (HDPFSDFS LS) VAI ACESSAR OS ARQUIVOS CONTIDOS DENTRO DO HDFS. (ESSES ARQUIVOS NAO APARECEM PARTICIONADOS)

	- TO CONJUNTO DE DADOS DO HDFS É CHAMADO DE DATALAKE

### HIVE ###

	O QUE É O HIVE -> É UM SOFTWARE DE DATAWAREHOUSE DESTINADO PARA LEITURA/ESCRITA/GERENCIAMENTO DE DATASETS.

	- ELE VAI LER O ARQUIVO EM FORMATO DE TABELA SE ELE FOR ESTRUTURADO EM LINHAS E COLUNAS USANDO A LINGUAGEM PROPRIA DELE "HQL"

	- HIVE NAO É BANCO DE DADOS, ELE É APENAS UMA CAMADA DE ACESSO.

	QUANDO CRIAMOS UM BANCO DE DADOS NO HIVE ELE VAI CRIANDO PASTAS, AS TABELAS SERÃO SUBPASTAS E OS DADOS VIRAM ARQUIVOS.


	DATASWAMP -> PANTANO DE DADOS (DATALAKE DESORGANIZADO)


### YARN ###

	O QUE É O YARN -> SISTEMA PARA GERENCIAMENTO DE JOBS

	RESOURCE MANAGER -> PEGA A REQUISIÇÃO E ANALISA O JOB QUE ESTA SENDO ENVIADO E DIVIDE AS TAREFAS.

	NAMEMANAGER -> AVALIA OS RECURSOS DA MAQUINA (CADA MAQUINA TEM UM NODE MANAGER)

	NA CRIAÇÃO DO JOB VOCE PODE PASSAR:

	1 - QUANTIDADE DE  MEMORIA RAM.
	2 - QUANTOS CORS DE MEMORIA VAI UTILIZAR.
	3 - DAR UM NOME AO JOB

	NA APLICAÇÃO WEB VOCE CONSEGUE:

	1 - CONSULTAR OS STATUS D JOB
	2 - CONSULTAR OS LOGS DO JOB (DURATE A EXECUÇÃO)
	3 - MATAR O JOB (ENCERRAR SESSAO)


	-------- IDEIAS DO MERCADO ---------
	EXTRAIR VALOR DOS DADOS PARA SE ANTECIPAR NO MERCADO


	-------- FONTE DE DADOS ---------
	TXT - INFORMAÇÕES DESESTRUTURADAS
	GRUPO DE WHATSAP
	BANCOS DE DADOS DESESTRUTURADOS



### MAP AND REDUCE / SPARK ###

	####### MAP AND REDUCE #######

	- O QUE É MAP REDUCE? É UM CONJUNTO DE CÓDIGOS PRONTOS NO QUAL CHAMAMOS DE FRAMEWORK. ESSE CONJUNTO DE CÓDIGOS PRONTOS DEPENDE DE ÚMA LINGUAGEM DE PROGRAMAÇÃO (PYTHON,JAVA OU SCALA)

	- MAP AND REDUCE PEGA O DADO DE UMA FONTE, VAI LER O DADO, VAI DISTRIBUIR ESSE DADO PELOS NÓS DO CLUSTER. 

	- MAP AND REDUCE PROCESSA TUDO EM DISCO (É MAIS LENTO DO QUE PROCESSAR EM MEMÓRIA) - DEIXOU DE SER TÃO UTILIZADO


	####### SPARK #######

	- SPARK PEGA O DADO DE UMA FONTE, VAI LER O DADO, VAI DISTRIBUIR ESSE DADO PELOS NÓS DO CLUSTER. 

	- SPARK PROCESSO TUDO EM MEMÓRIA (É MAIS RÁPIDO) -> MAIS UTILIZADO -> É MAIS EFICIENTE DO QUE O MAP REDUCE.





### ECOSSISTEMA HADOOP ###


	- SQOOP -> POR TRÁS É UM MAP REDUCE, CONECTA EM QUALQUER BANCO E INSERE NO HDFS. (PODE UTILIZAR UMA QUERY SQL)
	- FLUME -> TRABALHA EM LINHA DE COMANDO, IDEIA DELE É MOVER ARQUIVOS MUITO GRANDES. (PODE SER UTILZIADO EM MEMÓRIA OU EM DISCO) -> CONECTA COM PÁGINAS WEB.
	- NIFI -> PRATICAMENTE SUBSTITUI O FLUME. (GRANDE VARIEDADE DE CONEXÃO E TEM INTERFACE GRÁFICA)
	- KAFKA -> NÃO É UMA FERRAMENTA DO ECOSSISTEMA HADOOP. (ELE SERVE PARA FAZER UMA FILA DO QUE SERÁ ANALISADO, CENTRALIZA TUDO DENTRO DELE)
	- SPARK -> ELE SERVE PARA FAZER INGESTÃO, ANALISE DOS DADOS, MANIPULAR OS DADOS (REVÉS, NECESSITA DE MAIS TEMPO PARA FAZER INGESTÃO, POIS PRECISA FAZER UM PROGRAMA PARA FAZER A INGESTÃO DOS DADOS)
	- HDFS -> SÃO AS PASTAS ONDE VAI CONTER OS ARQUIVOS DISTRIBUIDOS
	- HIVE -> VAI LER OS ARQUIVOS DISTRIBUIDOS EM FORMATO RELACIONAL, SUPORTA A LINGUAGEM HQL. (FAZ CONSULTAS EM LOTE(EX: 1 MILHAO DE LINHAS) MAIS RÁPIDO QUE O HBASE)
	- HBASE -> BANCO DE DADOS COLUNAR BASEADO EM CHAVE E VALOR. (UTILIZADO PARA BASES MUITO GRANDES EXEMPLO 1 BILHÃO DE LINHAS -> FAZ CONSULTAS DE 1 LINHA COM MELHOR PERFORMANCE)
	- YARN -> MONITORA TODOS OS RECURSOS DO HADOOP
	- ZOOKEEPER -> KAFKA, HBASE UTILIZAM O ZOOKEEPER.




### CURIOSIDADES ###

- TEMOS PROBLEMAS DE PROCESSAMENTO HOJE EM DIA -> CONSEGUIMOS ARMAZENAR ESSA INFORMAÇÃO MAS TEMOS DIFICULDADE PARA PROCESSA-LA

- SCALA É BASEADO EM JAVA.

- QUAL FOI A SOLUÇÃO PARA PROCESSAMENTO DE BIG DATA?
- PROCESSAMENTO DISTRIBUIDO (NÃO SERVE PARA ARQUIVOS PEQUENOS -> SE FOR PEQUENO O BI CONVENCIONAL RESOLVE O PROBLEMA)

- WEBSCRAPING - > DOWLOAD DE PAGINAS WEB. -> PARA RESOLVER ESSE PROBLEMA QUE TINHAMOS NO PASSADO FOI CRIADO O PROCESSAMENTO DISTRIBUIDO.


- Todos os componentes do hadoop são desenvolvidos em Java

HADOOP USA MAQUINA DE BAIXO CUSTO -> 512GB DE RAM

ESCALAR VERTICAMENTE O SERVIDOR HADOOP -> COMPRAMOS UMA MAQUINA MAIS POTENTE

ESCALAR HORIZONTALMENTE O SERVIDOR HADOOP -> UM CLUSTER ESCALAMOS HORIZONTALMENTE, QUANDO A CAPACIDADE DO CLUSTER CHEGA AO FIM ADICIONAMOS MAIS UMA MAQUINA

#####################################################################



### O QUE ESTUDAR: ###

Python -> é utlizado para fazer analise. Tratar arquivo desestruturado. -> estudar isso - Estudar como tratar arquivo com python

Aprender o basico de linux


#####################################################################
