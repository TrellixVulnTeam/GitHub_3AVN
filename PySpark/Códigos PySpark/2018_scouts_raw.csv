from pyspark.sql.types import StructField,StringType,IntegerType,StructType
from pyspark.sql import SparkSession
from pyspark.sql import functions as F
from pyspark.sql.functions import lit #Apenas para criar o campo ano

appName='Tratamento Dados Cartola 2018'
sourcePathPartidas='/raw/db_cartola/2018/rodada-*.csv'
sourcePathJogadores='/raw/db_cartola/2018/2018_jogadores.csv'
sourcePathTimes='/raw/db_cartola/times_ids.csv'
managePath="/manage/2018_scouts" 
mode='append'
ano = 2018

spark = SparkSession.builder.appName(appName).config("spark.debug.maxToStringFields", "100").getOrCreate()

try:
    ## Montando o Schema para os dados dos arquivos (id precisa ser String pois vem Registros nulos)
    data_schema = [StructField('id',StringType(),True),StructField('atletasnome',StringType(),True),StructField('atletasslug',StringType(),True),StructField('atletasapelido',StringType(),True),StructField('atletasfoto',StringType(),True),StructField('Atleta',StringType(),True),StructField('Rodada',StringType(),True),StructField('Clube',StringType(),True),StructField('Posicao',StringType(),True),StructField('atletasstatus_id',StringType(),True),StructField('Pontos',StringType(),True),StructField('Preco',StringType(),True),StructField('PrecoVariacao',StringType(),True),StructField('PontosMedia',StringType(),True),StructField('atletasclubeidfullname',StringType(),True),StructField('FC',StringType(),True),StructField('FD',StringType(),True),StructField('FF',StringType(),True),StructField('FS',StringType(),True),StructField('G',StringType(),True),StructField('I',StringType(),True),StructField('RB',StringType(),True),StructField('CA',StringType(),True),StructField('PE',StringType(),True),StructField('A',StringType(),True),StructField('SG',StringType(),True),StructField('DD',StringType(),True),StructField('FT',StringType(),True),StructField('GS',StringType(),True),StructField('CV',StringType(),True),StructField('GC',StringType(),True)]
    times_schema = [
        StructField('nomecbf',StringType(),True),
        StructField('nomecartola', StringType(), True),
        StructField('nomecompleto', StringType(), True),
        StructField('codolder', StringType(), True),
        StructField('cod2017', StringType(), True),
        StructField('cod2018', StringType(), True),
        StructField('id', StringType(), True),
        StructField('abreviacao', StringType(), True),
        StructField('escudos6060', StringType(), True),
        StructField('escudos4545', StringType(), True),
        StructField('escudos3030', StringType(), True)]

    # Vinculando esse Schema em uma variavel
    estrutura = StructType(fields=data_schema)
    estrutura_times = StructType(fields=times_schema)

    # Importando os dados do HDFS e inserindo-os no Schema acima
    rodadas_2018 = spark.read.csv(sourcePathPartidas,schema=estrutura,header=False)
    times_2018 = spark.read.csv(sourcePathTimes,schema=estrutura_times,header=True)
    jogadores_2018 = spark.read.csv(sourcePathJogadores,header=True)

    # Retirando os headers que foram importados
    rodadas_2018 = rodadas_2018.where(F.col("id").isNotNull())

    # Renomeando os campos necessários e adicionando o campo Ano
    rodadas_2018 = rodadas_2018.withColumn("Ano", lit(ano))
    rodadas_2018 = rodadas_2018.withColumnRenamed('Atleta','Id_Atleta')
    jogadores_2018 = jogadores_2018.withColumnRenamed('atletas.atleta_id','Id_jogador')

    # Join com a tabela de jogadores
    rodadas_2018 = rodadas_2018.join(jogadores_2018,rodadas_2018.Id_Atleta == jogadores_2018.Id_jogador,"Inner")

    # Renomeando os campos necessários
    rodadas_2018 = rodadas_2018.withColumnRenamed('atletas.apelido','Atleta')

    rodadas_tratado_2018 = rodadas_2018.select(['Atleta','Rodada','Clube','Posicao','Pontos','PontosMedia','Preco','PrecoVariacao','Ano'])

    rodadas_tratado_2018.coalesce(1).write.format("csv").option("header", "True").mode(mode).save(managePath)

except:
  print("Error")