from pyspark.sql import SparkSession
from pyspark.sql.functions import lit #Apenas para criar o campo ano


appName='cartola_ano'
sourcePathPartidas='/raw/db_cartola/2015/2015_partidas_ids.csv'
sourcePathTimes='/raw/db_cartola/2015/2015_times.csv'
rawPath="/manage/2015_partidas" 
mode='append' 
ano = 2015

spark = SparkSession.builder.appName(appName).getOrCreate()

try:
	# Importando os arquivos do HDFS
	partidas_2015 = spark.read.csv(sourcePathPartidas,header=True)
	times_2015 = spark.read.csv(sourcePathTimes,header=True)

	# Renomeando colunas necess√°rias
	partidas_2015 = partidas_2015.withColumnRenamed('CasaID', 'Casa')
	partidas_2015 = partidas_2015.withColumnRenamed('VisitanteID', 'Visitante')
	partidas_2015 = partidas_2015.withColumnRenamed('ID','Id_partidas')
	times_2015 = times_2015.withColumnRenamed('ID','Id_times')

	# Join para pegar Time da casa
	partidas_2015 = partidas_2015.join(times_2015,partidas_2015.Casa == times_2015.Id_times,"inner")

	partidas_2015 = partidas_2015.select('Id_partidas','Rodada','Nome','Visitante','PlacarCasa','PlacarVisitante','Resultado')
	partidas_2015 = partidas_2015.withColumnRenamed('Nome','Casa')


	# Join para pegar o time visitante
	partidas_2015 = partidas_2015.join(times_2015,partidas_2015.Visitante == times_2015.Id_times,"inner")

	partidas_2015 = partidas_2015.select('Id_partidas','Rodada','Casa','Nome','PlacarCasa','PlacarVisitante','Resultado')
	partidas_2015 = partidas_2015.withColumnRenamed('Nome','Visitante')

	partidas_2015 = partidas_2015.withColumn("Ano", lit(ano))

	partidas_2015.coalesce(1).write.format("csv").option("header", "True").mode(mode).save(rawPath)

except:
  print("Error")